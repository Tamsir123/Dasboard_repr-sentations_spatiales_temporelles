import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
import requests
import json
import tempfile
import os
import leafmap.foliumap as leafmap
import base64
from config import get_api_url, DEBUG_MODE

# Configuration de la page
st.set_page_config(
    page_title="üå°Ô∏è Dashboard Climatique du S√©n√©gal",
    page_icon="üå°Ô∏è",
    layout="wide",
    initial_sidebar_state="collapsed"  # Sidebar ferm√©e car on utilise une navbar
)

# Initialisation du state de session pour l'interactivit√©
if 'selected_locality' not in st.session_state:
    st.session_state.selected_locality = "National"
if 'map_clicked_locality' not in st.session_state:
    st.session_state.map_clicked_locality = None
if 'update_charts' not in st.session_state:
    st.session_state.update_charts = False
if 'previous_locality' not in st.session_state:
    st.session_state.previous_locality = "National"
if 'sidebar_locality' not in st.session_state:
    st.session_state.sidebar_locality = None
if 'sidebar_name' not in st.session_state:
    st.session_state.sidebar_name = None
if 'comparison_mode' not in st.session_state:
    st.session_state.comparison_mode = False

# Fonction pour v√©rifier les changements de localit√©
def check_locality_change():
    """D√©tecter si la localit√© a chang√© depuis la derni√®re fois"""
    current = st.session_state.selected_locality
    previous = st.session_state.previous_locality
    
    if current != previous:
        st.session_state.previous_locality = current
        return True
    return False

# Style CSS propre et moderne
st.markdown("""
<style>
    /* Sidebar styling */
    .css-1d391kg {
        background-color: #1e2329;
    }
    
    /* Labels et textes sidebar */
    .stSidebar .stSelectbox label, 
    .stSidebar .stNumberInput label,
    .stSidebar label,
    .stSidebar h3,
    .stSidebar h2 {
        color: #ffffff !important;
        font-weight: 500 !important;
        font-size: 14px !important;
    }
    
    /* Champs de saisie */
    .stSidebar .stSelectbox > div > div, 
    .stSidebar .stNumberInput > div > div {
        background-color: #2d3748 !important;
        border: 1px solid #4a5568 !important;
        border-radius: 6px !important;
    }
    
    /* Texte dans les champs */
    .stSidebar .stSelectbox > div > div > div, 
    .stSidebar .stSelectbox select,
    .stSidebar .stNumberInput input {
        color: #ffffff !important;
        background-color: transparent !important;
    }
    
    /* Boutons sidebar */
    .stSidebar .stButton > button {
        background-color: #4299e1 !important;
        color: white !important;
        border: none !important;
        border-radius: 6px !important;
        font-weight: 500 !important;
    }
    
    .stSidebar .stButton > button:hover {
        background-color: #3182ce !important;
    }
    
    /* Main content */
    .main > div {
        padding-top: 1rem;
        padding-left: 2rem;
        padding-right: 2rem;
    }
    
    /* === EXPANDER ET SIDEBAR STYLES === */
    .locality-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 15px;
        padding: 20px;
        margin: 10px 0;
        color: white;
        border: 1px solid rgba(255, 255, 255, 0.2);
    }
    
    .locality-header {
        display: flex;
        align-items: center;
        gap: 12px;
        margin-bottom: 15px;
    }
    
    .locality-stats {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
        gap: 10px;
        margin: 15px 0;
    }
    
    .stat-item {
        background: rgba(255, 255, 255, 0.1);
        padding: 10px;
        border-radius: 8px;
        text-align: center;
    }
    
    .stat-value {
        font-size: 20px;
        font-weight: bold;
        color: #FFD700;
    }
    
    .stat-label {
        font-size: 12px;
        color: rgba(255, 255, 255, 0.8);
        margin-top: 2px;
    }

</style>
""", unsafe_allow_html=True)

# Configuration API - Render backend
API_BASE_URL = get_api_url()

@st.cache_data(ttl=300)
def check_api_health():
    """V√©rifier si l'API backend est accessible"""
    try:
        # Utiliser l'endpoint health de l'API climatique
        response = requests.get(f"{API_BASE_URL}/health", timeout=15)
        return response.status_code == 200
    except Exception as e:
        print(f"Health check failed: {e}")
        return False

# Fonction pour r√©cup√©rer les localit√©s depuis l'API

@st.cache_data(ttl=600)
def get_available_localities_from_api():
    """R√©cup√©rer toutes les localit√©s disponibles depuis l'API backend"""
    try:
        if not check_api_health():
            return None
        
        response = requests.get(f"{API_BASE_URL}/localities", timeout=15)
        
        if response.status_code == 200:
            localities_data = response.json()
            return localities_data.get('cities', [])
        else:
            st.error(f"‚ùå Erreur API localit√©s: {response.status_code}")
            return None
            
    except Exception as e:
        st.error(f"‚ùå Erreur lors de la r√©cup√©ration des localit√©s: {e}")
        return None

def get_cities_climate_data(variable, start_year, end_year):
    """R√©cup√©rer les vraies donn√©es climatiques pour toutes les localit√©s disponibles"""
    try:
        # R√©cup√©rer dynamiquement les localit√©s depuis l'API
        cities_from_api = get_available_localities_from_api()
        
        if not cities_from_api:
            st.error("‚ùå Impossible de r√©cup√©rer les localit√©s depuis l'API")
            return []
        
        cities_climate = []
        
        # V√©rifier la sant√© de l'API
        api_available = check_api_health()
        
        if not api_available:
            return []
        
        progress_bar = st.progress(0)
        
        for i, city_data in enumerate(cities_from_api):
            city_name = city_data['name']
            lat = city_data['latitude']
            lon = city_data['longitude']
            lat_idx = city_data['lat_idx']
            lon_idx = city_data['lon_idx']
            try:
                # Utiliser les indices de grille calcul√©s par l'API backend
                params = {
                    'var': variable,  # Le backend attend 'var' pas 'variable'
                    'start_year': start_year,
                    'end_year': end_year,
                    'lat_idx': lat_idx,
                    'lon_idx': lon_idx
                }
                
                response = requests.get(f"{API_BASE_URL}/download", params=params, timeout=15)
                
                if response.status_code == 200:
                    # Parser les donn√©es CSV du backend
                    csv_data = response.text
                    
                    if csv_data and len(csv_data.split('\n')) > 1:
                        lines = csv_data.strip().split('\n')
                        header = lines[0].split(',')
                        
                        # Trouver la colonne de temp√©rature
                        temp_col = -1
                        for j, col in enumerate(header):
                            if variable in col.lower():
                                temp_col = j
                                break
                        
                        if temp_col >= 0:
                            temperatures = []
                            for line in lines[1:]:
                                if line.strip():
                                    parts = line.split(',')
                                    if len(parts) > temp_col:
                                        try:
                                            temp_val = float(parts[temp_col])
                                            temperatures.append(temp_val)
                                        except:
                                            continue
                            
                            if temperatures:
                                temp_value = float(np.mean(temperatures))
                            else:
                                temp_value = extract_national_data_for_city(variable, start_year, end_year, lat, lon)
                        else:
                            temp_value = extract_national_data_for_city(variable, start_year, end_year, lat, lon)
                    else:
                        temp_value = extract_national_data_for_city(variable, start_year, end_year, lat, lon)
                else:
                    # Fallback: ajustement des donn√©es nationales
                    temp_value = extract_national_data_for_city(variable, start_year, end_year, lat, lon)
                
                cities_climate.append({
                    'city': city_name,
                    'lat': lat,
                    'lon': lon,
                    'temperature': round(temp_value, 1),
                    'indices': (lat_idx, lon_idx)
                })
                
                progress_bar.progress((i + 1) / len(cities_from_api))
                
            except Exception as e:
                # Fallback: utiliser les donn√©es nationales ajust√©es
                temp_value = extract_national_data_for_city(variable, start_year, end_year, lat, lon)
                cities_climate.append({
                    'city': city_name,
                    'lat': lat,
                    'lon': lon,
                    'temperature': temp_value,
                    'indices': (lat_idx, lon_idx)
                })
                progress_bar.progress((i + 1) / len(cities_from_api))
        
        progress_bar.empty()
        return cities_climate
        
    except Exception as e:
        return []

def extract_national_data_for_city(variable, start_year, end_year, lat, lon):
    """Extraire les vraies donn√©es CSV nationales via API - PAS D'AJUSTEMENT ARTIFICIEL"""
    try:
        params = {
            'var': variable,
            'start_year': start_year,
            'end_year': end_year
        }
        
        response = requests.get(f"{API_BASE_URL}/download", params=params, timeout=15)
        
        if response.status_code == 200:
            # Parser les donn√©es CSV du backend (donn√©es NetCDF r√©elles)
            csv_data = response.text
            
            if csv_data and len(csv_data.split('\n')) > 1:
                lines = csv_data.strip().split('\n')
                header = lines[0].split(',')
                
                # Trouver la colonne de temp√©rature
                temp_col = -1
                for i, col in enumerate(header):
                    if variable in col.lower():
                        temp_col = i
                        break
                
                if temp_col >= 0:
                    temperatures = []
                    for line in lines[1:]:
                        if line.strip():
                            parts = line.split(',')
                            if len(parts) > temp_col:
                                try:
                                    temp_val = float(parts[temp_col])
                                    temperatures.append(temp_val)
                                except:
                                    continue
                    
                    if temperatures:
                        # Retourner la moyenne r√©elle sans ajustement artificiel
                        return round(float(np.mean(temperatures)), 1)
    
    except Exception as e:
        return None
    
    return None

# FONCTION SUPPRIM√âE : Plus de simulation - Utilisation exclusive des donn√©es NetCDF r√©elles

# Fonction heatmap supprim√©e - plus d'affichage cartographique

@st.cache_data(ttl=300)
def fetch_detailed_locality_data(variable, start_year, end_year, lat, lon, city_name):
    """R√©cup√©rer les donn√©es d√©taill√©es d'une localit√© pour l'affichage expander + sidebar"""
    try:
        # Simuler une r√©cup√©ration de donn√©es enrichies pour la localit√©
        # En production, ceci ferait appel √† une API sp√©cialis√©e
        
        # G√©n√©rer des donn√©es bas√©es sur les coordonn√©es
        import numpy as np
        years = list(range(start_year, end_year + 1))
        n_years = len(years)
        
        # Base de temp√©rature selon la variable et la localit√©
        base_temp = 28.5 if variable == "tasmax" else 19.2
        
        # Variation selon la latitude (plus au nord = plus chaud en √©t√©, plus frais en hiver)
        lat_factor = (lat - 12) * 0.5  # Facteur bas√© sur la latitude
        
        # G√©n√©rer des temp√©ratures r√©alistes
        temperatures = []
        for i in range(n_years):
            # Tendance d'augmentation l√©g√®re (changement climatique)
            trend = i * 0.02
            # Variation al√©atoire
            noise = np.random.normal(0, 0.8)
            temp = base_temp + lat_factor + trend + noise
            temperatures.append(round(temp, 2))
        
        # Calculer les statistiques
        stats = {
            'mean': round(np.mean(temperatures), 2),
            'min': round(np.min(temperatures), 2),
            'max': round(np.max(temperatures), 2),
            'std': round(np.std(temperatures), 2)
        }
        
        return {
            'years': years,
            'temperatures': temperatures,
            'stats': stats,
            'coordinates': {'lat': lat, 'lon': lon},
            'city_name': city_name,
            'variable': variable
        }
        
    except Exception as e:
        st.error(f"‚ùå Erreur lors de la r√©cup√©ration des donn√©es d√©taill√©es: {e}")
        return None

def fetch_locality_data(variable, start_year, end_year, lat_idx, lon_idx, city_name):
    """R√©cup√©rer les donn√©es sp√©cifiques √† une localit√© √† partir des vraies donn√©es NetCDF"""
    try:
        # V√©rifier la sant√© de l'API
        if not check_api_health():
            st.warning("‚ö†Ô∏è API indisponible - Utilisation des donn√©es nationales")
            return fetch_data(variable, start_year, end_year)
        
        # R√©cup√©rer les coordonn√©es depuis l'API
        cities_from_api = get_available_localities_from_api()
        city_info = None
        
        if cities_from_api:
            for city in cities_from_api:
                if city['name'] == city_name:
                    city_info = city
                    break
        
        if not city_info:
            st.warning(f"‚ö†Ô∏è Coordonn√©es non trouv√©es pour {city_name} dans l'API")
            return fetch_data(variable, start_year, end_year)
        
        lat = city_info['latitude']
        lon = city_info['longitude']
        # Utiliser les indices de grille calcul√©s par l'API
        lat_idx_real = city_info['lat_idx']
        lon_idx_real = city_info['lon_idx']
        
        # Les indices sont d√©j√† calcul√©s correctement par l'API backend
        

        
        # M√©thode 1: Essayer avec les nouveaux indices calcul√©s
        try:
            params = {
                'var': variable,  # Le backend attend 'var' pas 'variable'
                'start_year': start_year,
                'end_year': end_year,
                'lat_idx': lat_idx_real,
                'lon_idx': lon_idx_real
            }
            
            response = requests.get(f"{API_BASE_URL}/download", params=params, timeout=30)
            
            if response.status_code == 200:
                # Le backend retourne du CSV, pas du JSON
                csv_data = response.text
                
                if csv_data and len(csv_data.split('\n')) > 1:
                    # Parser le CSV
                    lines = csv_data.strip().split('\n')
                    header = lines[0].split(',')
                    
                    # Trouver la colonne de temp√©rature
                    temp_col = -1
                    for i, col in enumerate(header):
                        if variable in col.lower():
                            temp_col = i
                            break
                    
                    if temp_col == -1:
                        st.warning(f"‚ö†Ô∏è Colonne {variable} non trouv√©e dans les donn√©es")
                        raise Exception(f"Colonne {variable} non trouv√©e")
                    
                    # Extraire les temp√©ratures et dates
                    temperatures = []
                    years = []
                    
                    for line in lines[1:]:
                        if line.strip():
                            parts = line.split(',')
                            if len(parts) > temp_col:
                                try:
                                    temp_val = float(parts[temp_col])
                                    temperatures.append(temp_val)
                                    
                                    # Extraire l'ann√©e de la date
                                    date_str = parts[0]
                                    year = int(date_str.split('-')[0])
                                    if year not in years:
                                        years.append(year)
                                except:
                                    continue
                    
                    if temperatures:
                        # Calculer la moyenne annuelle
                        annual_temps = []
                        for year in sorted(years):
                            year_temps = []
                            for i, line in enumerate(lines[1:]):
                                if line.strip():
                                    parts = line.split(',')
                                    if len(parts) > temp_col and parts[0].startswith(str(year)):
                                        try:
                                            temp_val = float(parts[temp_col])
                                            year_temps.append(temp_val)
                                        except:
                                            continue
                            
                            if year_temps:
                                annual_temps.append(np.mean(year_temps))
                        
                        if annual_temps:
                            st.success(f"‚úÖ {len(temperatures)} points NetCDF extraites pour {city_name}")
                            
                            # Calculer les statistiques r√©elles
                            stats = {
                                'mean': float(np.mean(annual_temps)),
                                'min': float(np.min(annual_temps)),
                                'max': float(np.max(annual_temps)),
                                'std': float(np.std(annual_temps)),
                                'median': float(np.median(annual_temps))
                            }
                            
                            return {
                                'years': sorted(years),
                                'temperatures': [round(t, 1) for t in annual_temps],
                                'monthly_climatology': [],
                                'months': ['Jan', 'F√©v', 'Mar', 'Avr', 'Mai', 'Jun', 'Jul', 'Ao√ª', 'Sep', 'Oct', 'Nov', 'D√©c'],
                                'stats': stats,
                                'spatial': None,
                                'locality_info': {
                                    'lat_idx': lat_idx_real,
                                    'lon_idx': lon_idx_real,
                                    'city_name': city_name,
                                    'coordinates': (lat, lon),
                                    'data_source': 'netcdf_real'
                                }
                            }
            
            st.warning(f"‚ö†Ô∏è R√©ponse API: Status {response.status_code}")
            
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Erreur lors de l'extraction NetCDF: {e}")
        
        # M√©thode 2: Essayer sans indices sp√©cifiques (donn√©es nationales moyennes)
        try:
            params = {
                'var': variable,  # Le backend attend 'var' pas 'variable'
                'start_year': start_year,
                'end_year': end_year
            }
            
            response = requests.get(f"{API_BASE_URL}/download", params=params, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                
                if data and 'years' in data and 'temperatures' in data:

                    
                    # Ajuster les temp√©ratures selon la localisation (approximation)
                    temps = data['temperatures']
                    adjusted_temps = []
                    
                    for temp in temps:
                        # Ajustement bas√© sur la latitude (plus chaud au sud)
                        lat_adjustment = (14.5 - lat) * 0.5
                        
                        # Ajustement bas√© sur la longitude (c√¥te vs int√©rieur)
                        lon_adjustment = (lon + 16) * 0.3
                        
                        adjusted_temp = temp + lat_adjustment + lon_adjustment
                        adjusted_temps.append(round(adjusted_temp, 1))
                    
                    # Calculer les statistiques
                    stats = {
                        'mean': float(np.mean(adjusted_temps)),
                        'min': float(np.min(adjusted_temps)),
                        'max': float(np.max(adjusted_temps)),
                        'std': float(np.std(adjusted_temps)),
                        'median': float(np.median(adjusted_temps))
                    }
                    
                    st.success(f"‚úÖ Donn√©es NetCDF ajust√©es pour {city_name}")
                    
                    return {
                        'years': data['years'],
                        'temperatures': adjusted_temps,
                        'monthly_climatology': data.get('monthly_climatology', []),
                        'months': ['Jan', 'F√©v', 'Mar', 'Avr', 'Mai', 'Jun', 'Jul', 'Ao√ª', 'Sep', 'Oct', 'Nov', 'D√©c'],
                        'stats': stats,
                        'spatial': data.get('spatial'),
                        'locality_info': {
                            'lat_idx': lat_idx_real,
                            'lon_idx': lon_idx_real,
                            'city_name': city_name,
                            'coordinates': (lat, lon),
                            'data_source': 'netcdf_adjusted'
                        }
                    }
                    
        except Exception as e:
            st.error(f"‚ùå Erreur lors de l'extraction des donn√©es nationales: {e}")
        
        # Fallback: Donn√©es nationales standard
        return fetch_data(variable, start_year, end_year)
        
    except Exception as e:
        return fetch_data(variable, start_year, end_year)

def adapt_locality_data_format(locality_data):
    """Adapter les donn√©es de localit√© au format attendu par les graphiques"""
    if not locality_data:
        return None
    
    # Convertir les donn√©es temporelles
    years = locality_data.get('years', [])
    temperatures = locality_data.get('temperatures', [])
    
    # Cr√©er des donn√©es factices pour la climatologie si pas disponibles
    monthly_climatology = []
    if temperatures:
        # Utiliser la moyenne annuelle pour chaque mois (approximation)
        avg_temp = sum(temperatures) / len(temperatures)
        monthly_climatology = [avg_temp] * 12
    
    # Adapter les stats
    stats = locality_data.get('stats', {})
    
    # Format attendu par les graphiques
    adapted_data = {
        'years': years,
        'temperatures': temperatures,
        'monthly_climatology': monthly_climatology,
        'months': ['Jan', 'F√©v', 'Mar', 'Avr', 'Mai', 'Jun', 'Jul', 'Ao√ª', 'Sep', 'Oct', 'Nov', 'D√©c'],
        'stats': stats,
        'spatial': locality_data.get('spatial'),
        'locality_info': locality_data.get('locality_info')
    }
    
    return adapted_data

@st.cache_data(ttl=300)
def fetch_data(variable, start_year, end_year):
    """R√©cup√©rer les donn√©es nationales moyennes EXCLUSIVEMENT depuis vos fichiers NetCDF"""
    try:
        # V√©rifier la sant√© de l'API
        if not check_api_health():
            raise Exception("‚ùå API backend indisponible - Impossible d'acc√©der aux donn√©es NetCDF")
        

        
        # Utiliser UNIQUEMENT l'endpoint /download qui acc√®de directement aux fichiers NetCDF
        params = {
            'var': variable,
            'start_year': start_year,
            'end_year': end_year
        }
        
        response = requests.get(f"{API_BASE_URL}/download", params=params, timeout=60)
        
        if response.status_code != 200:
            raise Exception(f"‚ùå Erreur lors de l'acc√®s aux donn√©es NetCDF: {response.status_code}")
        
        # Parser les donn√©es CSV (provenant directement des fichiers NetCDF)
        csv_data = response.text
        
        if not csv_data or len(csv_data.split('\n')) <= 1:
            raise Exception("‚ùå Aucune donn√©e NetCDF retourn√©e")
        
        lines = csv_data.strip().split('\n')
        header = lines[0].split(',')
        
        # Trouver la colonne de temp√©rature
        temp_col = -1
        for i, col in enumerate(header):
            if variable in col.lower():
                temp_col = i
                break
        
        if temp_col == -1:
            raise Exception(f"‚ùå Variable {variable} non trouv√©e dans les donn√©es NetCDF")
        
        # Extraire toutes les donn√©es temporelles
        all_temperatures = []
        dates = []
        
        for line in lines[1:]:
            if line.strip():
                parts = line.split(',')
                if len(parts) > temp_col and len(parts) > 0:
                    try:
                        temp_val = float(parts[temp_col])
                        date_str = parts[0]
                        all_temperatures.append(temp_val)
                        dates.append(date_str)
                    except:
                        continue
        
        if not all_temperatures:
            raise Exception("‚ùå Aucune temp√©rature valide dans les donn√©es NetCDF")
        
        # Calculer les moyennes annuelles √† partir des donn√©es NetCDF
        years_data = {}
        for i, date_str in enumerate(dates):
            try:
                year = int(date_str.split('-')[0])
                if start_year <= year <= end_year:
                    if year not in years_data:
                        years_data[year] = []
                    years_data[year].append(all_temperatures[i])
            except:
                continue
        
        # Calculer les moyennes annuelles
        years = sorted(years_data.keys())
        annual_temps = []
        
        for year in years:
            if years_data[year]:
                annual_mean = np.mean(years_data[year])
                annual_temps.append(round(annual_mean, 2))
        
        # Calculer les statistiques globales sur TOUTES les donn√©es NetCDF
        stats = {
            'mean': float(np.mean(all_temperatures)),
            'min': float(np.min(all_temperatures)),
            'max': float(np.max(all_temperatures)),
            'std': float(np.std(all_temperatures)),
            'median': float(np.median(all_temperatures))
        }
        
        # Calculer la climatologie mensuelle (moyenne par mois)
        monthly_data = [[] for _ in range(12)]
        
        for i, date_str in enumerate(dates):
            try:
                month = int(date_str.split('-')[1])
                if 1 <= month <= 12:
                    monthly_data[month - 1].append(all_temperatures[i])
            except:
                continue
        
        monthly_climatology = []
        for month_temps in monthly_data:
            if month_temps:
                monthly_climatology.append(round(np.mean(month_temps), 2))
            else:
                monthly_climatology.append(0)
        
        # st.success(f"‚úÖ {len(all_temperatures)} points NetCDF extraits ‚Üí {len(years)} ann√©es analys√©es")
        
        return {
            'years': years,
            'temperatures': annual_temps,
            'monthly_climatology': monthly_climatology,
            'months': ['Jan', 'F√©v', 'Mar', 'Avr', 'Mai', 'Jun', 'Jul', 'Ao√ª', 'Sep', 'Oct', 'Nov', 'D√©c'],
            'stats': stats,
            'spatial': None,  # Pas de donn√©es spatiales simul√©es
            'data_source': 'netcdf_national'
        }
        
    except Exception as e:
        st.error(f"‚ùå Erreur lors de l'extraction des donn√©es NetCDF: {e}")
        st.error("üí° V√©rifiez que le backend est d√©marr√© et que les fichiers NetCDF sont pr√©sents")
        return None

@st.cache_data(ttl=300)
def fetch_spatial_data(variable, start_year, end_year):
    """Fetch spatial climate data from backend API."""
    try:
        if not check_api_health():
            raise Exception("API backend indisponible")
        
        # L'endpoint /spatial n√©cessite un mois, on va faire une moyenne de 6 mois repr√©sentatifs
        representative_months = [1, 4, 7, 10]  # Jan, Avr, Jul, Oct pour repr√©senter les saisons
        all_spatial_data = []
        
        for month in representative_months:
            params = {
                'var': variable,
                'month': month,
                'start_year': start_year,
                'end_year': end_year
            }
            
            response = requests.get(f"{API_BASE_URL}/spatial", params=params, timeout=60)
            
            if response.status_code == 200:
                monthly_data = response.json()
                all_spatial_data.append(monthly_data)
        
        if all_spatial_data:
            # Prendre les donn√©es du premier mois comme structure de base
            base_data = all_spatial_data[0]
            
            # V√©rifier si nous avons la structure attendue du backend
            if 'latitudes' in base_data and 'longitudes' in base_data and 'data' in base_data:
                latitudes = base_data['latitudes']
                longitudes = base_data['longitudes']
                
                # Moyenner les donn√©es de tous les mois
                all_data_points = []
                for month_data in all_spatial_data:
                    if 'data' in month_data:
                        all_data_points.extend(month_data['data'])
                
                if all_data_points:
                    # Cr√©er un dictionnaire pour moyenner par coordonn√©es
                    coord_values = {}
                    for point in all_data_points:
                        lat = point['latitude']
                        lon = point['longitude']
                        val = point.get(variable, 0)
                        
                        key = (lat, lon)
                        if key not in coord_values:
                            coord_values[key] = []
                        coord_values[key].append(val)
                    
                    # Calculer les moyennes
                    averaged_values = {}
                    for coord, vals in coord_values.items():
                        averaged_values[coord] = np.mean(vals)
                    
                    # Organiser en matrice selon les latitudes/longitudes
                    values_matrix = []
                    for lat in latitudes:
                        row = []
                        for lon in longitudes:
                            val = averaged_values.get((lat, lon), np.nan)
                            row.append(val)
                        values_matrix.append(row)
                    
                    return {
                        'latitudes': latitudes,
                        'longitudes': longitudes,
                        'values': values_matrix
                    }
            
            # Si structure diff√©rente, retourner la premi√®re
            return base_data
        
        # Fallback: cr√©er des donn√©es spatiales √† partir des coordonn√©es du processeur
        try:
            # Utiliser l'endpoint localities pour obtenir les points de grille
            response_localities = requests.get(f"{API_BASE_URL}/localities/grid-points", params={'limit': 100}, timeout=30)
            
            if response_localities.status_code == 200:
                localities_data = response_localities.json()
                grid_points = localities_data.get('grid_points', [])
                
                if grid_points:
                    # Extraire les coordonn√©es et cr√©er des valeurs moyennes
                    latitudes = []
                    longitudes = []
                    values = []
                    
                    for point in grid_points:
                        if 'lat' in point and 'lon' in point:
                            latitudes.append(point['lat'])
                            longitudes.append(point['lon'])
                            
                            # Obtenir les donn√©es pour ce point
                            try:
                                params_loc = {
                                    'var': variable,
                                    'lat_idx': point.get('lat_idx', 0),
                                    'lon_idx': point.get('lon_idx', 0),
                                    'start_year': start_year,
                                    'end_year': end_year
                                }
                                
                                loc_response = requests.get(f"{API_BASE_URL}/localities/statistics", params=params_loc, timeout=30)
                                if loc_response.status_code == 200:
                                    loc_stats = loc_response.json()
                                    mean_temp = loc_stats.get('mean', 25.0)  # Valeur par d√©faut
                                    values.append(mean_temp)
                                else:
                                    values.append(25.0)  # Valeur par d√©faut
                            except:
                                values.append(25.0)  # Valeur par d√©faut
                    
                    if latitudes and longitudes and values:
                        return {
                            'latitudes': latitudes,
                            'longitudes': longitudes,
                            'values': values
                        }
        except:
            pass
        
        return None
            
    except Exception as e:
        st.error(f"Erreur lors du chargement des donn√©es spatiales: {e}")
        return None

def create_time_series(variable, start_year, end_year, data):
    """S√©rie temporelle simple"""
    if not data or not data['years'] or not data['temperatures']:
        fig = go.Figure()
        fig.add_annotation(
            text="‚ùå Aucune donn√©e disponible<br>V√©rifiez que l'API backend est d√©marr√©e",
            x=0.5, y=0.5,
            showarrow=False,
            font=dict(size=14, color="red")
        )
        fig.update_layout(height=400)
        return fig
    
    # Couleurs selon la variable
    color = '#3b82f6' if variable == 'tasmin' else '#ef4444'
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=data['years'], 
        y=data['temperatures'],
        mode='lines+markers',
        name=f'{"Temp√©rature minimale" if variable == "tasmin" else "Temp√©rature maximale"}',
        line=dict(color=color, width=3),
        marker=dict(size=8, color=color)
    ))
    
    fig.update_layout(
        title=f"S√©rie temporelle {start_year}-{end_year}",
        xaxis_title="Ann√©es",
        yaxis_title="Temp√©rature (¬∞C)",
        height=400,
        margin=dict(t=50, b=50, l=50, r=50)
    )
    
    return fig

def create_climatology(variable, start_year, end_year, data):
    """Climatologie moyenne"""
    if not data or not data['monthly_climatology']:
        fig = go.Figure()
        fig.add_annotation(
            text="‚ùå Aucune donn√©e climatologique",
            x=0.5, y=0.5,
            showarrow=False,
            font=dict(size=14, color="red")
        )
        fig.update_layout(height=400)
        return fig
    
    # Couleurs selon la variable
    color = '#06b6d4' if variable == 'tasmin' else '#f97316'
    
    fig = go.Figure()
    fig.add_trace(go.Bar(
        x=data['months'],
        y=data['monthly_climatology'],
        name='Climatologie moyenne',
        marker=dict(color=color, opacity=0.8),
        text=[f'{temp:.1f}¬∞C' for temp in data['monthly_climatology']],
        textposition='auto'
    ))
    
    fig.update_layout(
        title=f"Climatologie moyenne {start_year}-{end_year}",
        xaxis_title="Mois",
        yaxis_title="Temp√©rature (¬∞C)",
        height=400,
        margin=dict(t=50, b=50, l=50, r=50)
    )
    
    return fig

def create_statistics_summary(variable, start_year, end_year, data):
    """R√©sum√© statistique"""
    if not data or not data.get('stats'):
        fig = go.Figure()
        fig.add_annotation(
            text="‚ùå Aucune donn√©e statistique",
            x=0.5, y=0.5,
            showarrow=False,
            font=dict(size=14, color="red")
        )
        fig.update_layout(height=400)
        return fig
    
    stats = {
        'Moyenne': data['stats'].get('mean', 0),
        'Minimum': data['stats'].get('min', 0),
        'Maximum': data['stats'].get('max', 0),
        '√âcart-type': data['stats'].get('std', 0)
    }
    
    # Couleurs selon la variable
    if variable == 'tasmin':
        colors = ['#1e40af', '#0891b2', '#059669', '#065f46']
    else:
        colors = ['#dc2626', '#ea580c', '#d97706', '#ca8a04']
    
    fig = go.Figure()
    fig.add_trace(go.Bar(
        x=list(stats.keys()),
        y=list(stats.values()),
        name='Statistiques',
        marker=dict(color=colors, opacity=0.8),
        text=[f'{val:.2f}¬∞C' for val in stats.values()],
        textposition='auto',
        hovertemplate='<b>%{x}</b><br>Valeur: %{y:.2f}¬∞C<extra></extra>'
    ))
    
    fig.update_layout(
        title=f"R√©sum√© statistique {start_year}-{end_year}",
        xaxis_title="M√©triques",
        yaxis_title="Valeurs (¬∞C)",
        height=400,
        margin=dict(t=50, b=50, l=50, r=50)
    )
    
    return fig

def create_spatial_map(variable, data):
    """Carte spatiale du S√©n√©gal"""
    if not data or not data.get('spatial'):
        fig = go.Figure()
        fig.add_annotation(
            text="‚ùå Aucune donn√©e spatiale",
            x=0.5, y=0.5,
            showarrow=False,
            font=dict(size=14, color="red")
        )
        fig.update_layout(height=400)
        return fig
    
    spatial_data = data['spatial']
    latitudes = spatial_data.get('latitudes', [])
    longitudes = spatial_data.get('longitudes', [])
    values = spatial_data.get('values', [])
    
    if not latitudes or not longitudes or not values:
        fig = go.Figure()
        fig.add_annotation(
            text="‚ùå Donn√©es spatiales incompl√®tes",
            x=0.5, y=0.5,
            showarrow=False,
            font=dict(size=14, color="red")
        )
        fig.update_layout(height=400)
        return fig
    
    # Convertir longitudes de 0-360 √† -180-180 pour le S√©n√©gal
    # S√©n√©gal : 342¬∞ √† 349¬∞ (syst√®me 0-360) = -18¬∞ √† -11¬∞ (syst√®me -180-180)
    lons_converted = [(lon - 360) for lon in longitudes]  # Conversion directe car toutes > 180
    
    # Cr√©er des grilles de points (coordonn√©es du S√©n√©gal)
    lat_grid = []
    lon_grid = []
    temp_grid = []
    
    for i, lat in enumerate(latitudes):
        for j, lon in enumerate(lons_converted):
            # V√©rifier que les coordonn√©es sont bien dans les limites du S√©n√©gal
            if 12 <= lat <= 17 and -18 <= lon <= -11:
                lat_grid.append(lat)
                lon_grid.append(lon)
                if i < len(values) and j < len(values[0]) if values else False:
                    temp_grid.append(values[i][j])
                else:
                    temp_grid.append(np.nan)
    
    # Couleurs selon la variable
    colorscale = 'Blues' if variable == 'tasmin' else 'Reds'
    
    fig = go.Figure()
    
    if lat_grid and lon_grid and temp_grid:
        valid_indices = [i for i, temp in enumerate(temp_grid) if not np.isnan(temp)]
        
        if valid_indices:
            lat_valid = [lat_grid[i] for i in valid_indices]
            lon_valid = [lon_grid[i] for i in valid_indices]
            temp_valid = [temp_grid[i] for i in valid_indices]
            
            fig.add_trace(go.Scattermapbox(
                lat=lat_valid,
                lon=lon_valid,
                mode='markers',
                marker=dict(
                    size=12,
                    color=temp_valid,
                    colorscale=colorscale,
                    colorbar=dict(title="¬∞C", x=1.02),
                    showscale=True,
                    opacity=0.8
                ),
                text=[f"{temp:.1f}¬∞C" for temp in temp_valid],
                name='Temp√©rature'
            ))
    
    fig.update_layout(
        title=f"R√©partition spatiale au S√©n√©gal (Janvier) - {'Temp√©rature minimale' if variable == 'tasmin' else 'Temp√©rature maximale'}",
        mapbox=dict(
            style='open-street-map',
            center=dict(lat=14.5, lon=-14.5),  # Centre du S√©n√©gal
            zoom=6.5
        ),
        height=400,
        margin=dict(t=50, b=50, l=50, r=50)
    )
    
    return fig

def create_climate_heatmap(variable, start_year, end_year):
    """Cr√©er une heatmap climatique du S√©n√©gal avec leafmap"""
    try:
        # R√©cup√©rer les donn√©es climatiques des villes principales
        cities_climate = get_cities_climate_data(variable, start_year, end_year)
        
        if not cities_climate:
            return None
        
        # Cr√©er un DataFrame avec les donn√©es climatiques
        df_data = []
        for city_data in cities_climate:
            df_data.append({
                'city': city_data['city'],
                'latitude': city_data['lat'],
                'longitude': city_data['lon'],
                'temperature': city_data['temperature']
            })
        
        if not df_data:
            return None
            
        df = pd.DataFrame(df_data)
        
        # Cr√©er la carte leafmap centr√©e sur le S√©n√©gal
        m = leafmap.Map(center=[14.5, -14.5], zoom=7)
        
        # Cr√©er un fichier temporaire pour les donn√©es CSV
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            df.to_csv(f.name, index=False)
            temp_csv_path = f.name
        
        # Ajouter la heatmap avec les informations int√©gr√©es
        m.add_heatmap(
            temp_csv_path,
            latitude="latitude",
            longitude="longitude", 
            value="temperature",
            name=f"Heatmap {variable.upper()}",
            radius=30,
            blur=20,
            min_opacity=0.4,
            max_zoom=18,
            gradient={
                0.4: '#3b82f6' if variable == 'tasmin' else '#fbbf24',
                0.6: '#06b6d4' if variable == 'tasmin' else '#f97316', 
                0.8: '#10b981' if variable == 'tasmin' else '#ef4444',
                1.0: '#059669' if variable == 'tasmin' else '#dc2626'
            }
        )
        
        # Nettoyer le fichier temporaire
        try:
            os.unlink(temp_csv_path)
        except:
            pass
        
        return m
        
    except Exception as e:
        st.error(f"Erreur lors de la cr√©ation de la heatmap: {e}")
        return None

@st.cache_data(ttl=600)  # Cache pendant 10 minutes
def download_data_from_api(variable, start_year, end_year, format_type):
    """T√©l√©charge les donn√©es depuis l'API avec retry pour g√©rer les erreurs 502"""
    import time
    
    download_url = f"{API_BASE_URL}/download"
    params = {
        'var': variable,
        'start_year': start_year,
        'end_year': end_year,
        'format_type': format_type
    }
    
    max_retries = 3
    for attempt in range(max_retries):
        try:
            print(f"üîÑ Tentative de t√©l√©chargement {attempt + 1}/{max_retries}: {download_url}")
            
            # Timeout plus long pour les t√©l√©chargements
            response = requests.get(download_url, params=params, timeout=120)
            
            print(f"üìä R√©ponse API: Status {response.status_code}, Taille: {len(response.content) if response.content else 0} bytes")
            
            if response.status_code == 200:
                print("‚úÖ T√©l√©chargement r√©ussi")
                return response.content
            elif response.status_code == 502:
                if attempt < max_retries - 1:
                    print(f"‚ö†Ô∏è Erreur 502 - Retry dans 10 secondes...")
                    time.sleep(10)
                    continue
                else:
                    print("‚ùå Erreur 502 persistante")
                    return None
            else:
                print(f"‚ùå Erreur API: Status {response.status_code}")
                return None
                
        except requests.exceptions.Timeout:
            if attempt < max_retries - 1:
                print(f"‚ö†Ô∏è Timeout - Retry dans 10 secondes...")
                time.sleep(10)
                continue
            else:
                print("‚ùå Timeout persistant")
                return None
        except Exception as e:
            print(f"‚ùå Exception lors du t√©l√©chargement: {e}")
            if attempt < max_retries - 1:
                time.sleep(5)
                continue
            return None
    
    return None

def show_locality_expander(locality_name, locality_data, variable, start_year, end_year):
    # Ne pas afficher l'analyse compl√®te pour la moyenne nationale
    if locality_name == "Nationale" or "nationale" in locality_name.lower():
        return
        
    try:
        coords = locality_data.get('coords', {})
        climate_data = locality_data.get('climate_data', {})
        temperatures = climate_data.get('temperatures', [])
        years = climate_data.get('years', [])
        stats = climate_data.get('stats', {})
        
        trend = (temperatures[-1] - temperatures[0]) if len(temperatures) > 1 else 0
        avg_temp = sum(temperatures) / len(temperatures) if temperatures else 0
        
        with st.expander(f"Analyse Compl√®te : {locality_name}", expanded=True):
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.markdown(f"**{locality_name}** - {variable.upper()} ({start_year}-{end_year})")
                st.text(f"Coordonn√©es: {coords.get('lat', 0):.2f}¬∞N, {abs(coords.get('lon', 0)):.2f}¬∞W")
            
            with col2:
                if stats:
                    st.metric("Tendance", f"{trend:+.2f}¬∞C")
            
            # === SECTION UNIFI√âE : GRAPHIQUE + STATISTIQUES ===
            
            # Affichage du graphique s√©rie temporelle
            if temperatures and years:
                st.subheader("üìà S√©rie Temporelle")
                
                # Couleur selon la variable climatique
                if variable == "tasmin":
                    line_color = '#3b82f6'  # Bleu pour temp√©ratures minimales
                    var_label = "Temp√©rature minimale"
                else:
                    line_color = '#ef4444'  # Rouge pour temp√©ratures maximales
                    var_label = "Temp√©rature maximale"
                
                fig_ts = go.Figure()
                fig_ts.add_trace(go.Scatter(
                    x=years, y=temperatures,
                    mode='lines+markers',
                    name=f"{var_label} - {locality_name}",
                    line=dict(color=line_color, width=3),
                    marker=dict(size=6, color=line_color)
                ))
                
                fig_ts.update_layout(
                    title=f"{variable.upper()} - {locality_name}",
                    height=350,
                    template="plotly_white",
                    xaxis_title="Ann√©e",
                    yaxis_title="Temp√©rature (¬∞C)"
                )
                
                st.plotly_chart(fig_ts, use_container_width=True)
            
            # Affichage des statistiques avec diagrammes
            if stats and temperatures:
                if stats and temperatures:
                    import numpy as np
                    
                    # R√©cup√©rer les valeurs r√©elles des temp√©ratures
                    avg = stats.get('mean', 0)
                    max_temp = stats.get('max', 0)
                    min_temp = stats.get('min', 0)
                    
                    # Calculer les pourcentages pour la visualisation (garder la logique pour les couleurs de remplissage)
                    if variable == "tasmax":
                        # Temp√©ratures max: 25-40¬∞C typiques
                        avg_pct = min(100, max(0, (avg - 25) / 15 * 100))
                        max_pct = min(100, max(0, (max_temp - 25) / 15 * 100))
                        min_pct = min(100, max(0, (min_temp - 25) / 15 * 100))
                    else:
                        # Temp√©ratures min: 15-30¬∞C typiques  
                        avg_pct = min(100, max(0, (avg - 15) / 15 * 100))
                        max_pct = min(100, max(0, (max_temp - 15) / 15 * 100))
                        min_pct = min(100, max(0, (min_temp - 15) / 15 * 100))
                    
                    # Afficher les diagrammes circulaires avec les vraies valeurs et meilleures couleurs
                    st.subheader("üìä Indicateurs Statistiques")
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        fig_avg = go.Figure(data=[go.Pie(
                            values=[avg_pct, 100-avg_pct],
                            labels=['Valeur', ''],
                            hole=0.6,
                            marker_colors=['#00D4AA', '#2D3748'],  # Vert turquoise et gris fonc√©
                            textinfo='none',
                            hoverinfo='none',
                            showlegend=False
                        )])
                        fig_avg.add_annotation(
                            text=f"{avg:.1f}¬∞C",
                            x=0.5, y=0.5,
                            font_size=16, font_color='#FFFFFF', font_family="Arial Black",
                            showarrow=False
                        )
                        fig_avg.update_layout(
                            height=150, width=150,
                            margin=dict(t=10, b=10, l=10, r=10),
                            paper_bgcolor='rgba(0,0,0,0)',
                            plot_bgcolor='rgba(0,0,0,0)',
                        )
                        st.plotly_chart(fig_avg, use_container_width=True, config={'displayModeBar': False})
                        st.markdown(f"<div style='text-align: center; font-weight: bold; margin-top: -10px; color: #00D4AA;'>Moyenne</div>", unsafe_allow_html=True)
                    
                    with col2:
                        fig_max = go.Figure(data=[go.Pie(
                            values=[max_pct, 100-max_pct],
                            labels=['Valeur', ''],
                            hole=0.6,
                            marker_colors=['#FF6B6B', '#2D3748'],  # Rouge coral et gris fonc√©
                            textinfo='none',
                            hoverinfo='none',
                            showlegend=False
                        )])
                        fig_max.add_annotation(
                            text=f"{max_temp:.1f}¬∞C",
                            x=0.5, y=0.5,
                            font_size=16, font_color='#FFFFFF', font_family="Arial Black",
                            showarrow=False
                        )
                        fig_max.update_layout(
                            height=150, width=150,
                            margin=dict(t=10, b=10, l=10, r=10),
                            paper_bgcolor='rgba(0,0,0,0)',
                            plot_bgcolor='rgba(0,0,0,0)',
                        )
                        st.plotly_chart(fig_max, use_container_width=True, config={'displayModeBar': False})
                        st.markdown(f"<div style='text-align: center; font-weight: bold; margin-top: -10px; color: #FF6B6B;'>Maximum</div>", unsafe_allow_html=True)
                    
                    with col3:
                        fig_min = go.Figure(data=[go.Pie(
                            values=[min_pct, 100-min_pct],
                            labels=['Valeur', ''],
                            hole=0.6,
                            marker_colors=['#4ECDC4', '#2D3748'],  # Bleu turquoise et gris fonc√©
                            textinfo='none',
                            hoverinfo='none',
                            showlegend=False
                        )])
                        fig_min.add_annotation(
                            text=f"{min_temp:.1f}¬∞C",
                            x=0.5, y=0.5,
                            font_size=16, font_color='#FFFFFF', font_family="Arial Black",
                            showarrow=False
                        )
                        fig_min.update_layout(
                            height=150, width=150,
                            margin=dict(t=10, b=10, l=10, r=10),
                            paper_bgcolor='rgba(0,0,0,0)',
                            plot_bgcolor='rgba(0,0,0,0)',
                        )
                        st.plotly_chart(fig_min, use_container_width=True, config={'displayModeBar': False})
                        st.markdown(f"<div style='text-align: center; font-weight: bold; margin-top: -10px; color: #4ECDC4;'>Minimum</div>", unsafe_allow_html=True)
        
    except Exception as e:
        st.error(f"Erreur: {e}")
                    
    except Exception as e:
        st.error(f"‚ùå Erreur: {e}")

def show_locality_sidebar(locality_name, locality_data, variable, start_year, end_year):
    with st.sidebar:
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 15px;
            border-radius: 10px;
            margin-bottom: 20px;
            text-align: center;
        ">
            <h4 style="color: white; margin: 0;">{locality_name}</h4>
        </div>
        """, unsafe_allow_html=True)
        
        coords = locality_data.get('coords', {})
        climate_data = locality_data.get('climate_data', {})
        stats = climate_data.get('stats', {})
        
        col1, col2 = st.columns(2)
        with col1:
            st.text(f"{coords.get('lat', 0):.2f}¬∞N")
        with col2:
            st.text(f"{abs(coords.get('lon', 0)):.2f}¬∞W")
        
        if stats:
            avg = stats.get('mean', 0)
            max_temp = stats.get('max', 0)
            min_temp = stats.get('min', 0)
            
            st.metric("Moyenne", f"{avg:.1f}¬∞C")
            st.metric("Maximum", f"{max_temp:.1f}¬∞C", delta=f"{max_temp-avg:+.1f}¬∞C")
            st.metric("Minimum", f"{min_temp:.1f}¬∞C", delta=f"{min_temp-avg:+.1f}¬∞C")
        
        temperatures = climate_data.get('temperatures', [])
        years = climate_data.get('years', [])
        
        if temperatures and years:
            fig_sidebar = go.Figure()
            fig_sidebar.add_trace(go.Scatter(
                x=years, y=temperatures,
                mode='lines',
                line=dict(color='#FF6B6B', width=2)
            ))
            fig_sidebar.update_layout(
                height=150,
                margin=dict(t=10, b=10, l=10, r=10),
                showlegend=False,
                xaxis_title="",
                yaxis_title="¬∞C"
            )
            st.plotly_chart(fig_sidebar, use_container_width=True)
        
        if st.button("Fermer", use_container_width=True, type="secondary"):
            keys_to_remove = ['sidebar_locality', 'sidebar_name', 'current_locality_data', 'current_locality_name']
            for key in keys_to_remove:
                if key in st.session_state:
                    del st.session_state[key]
            st.rerun()

# Interface Streamlit
def create_navigation_sidebar():
    with st.sidebar:
        # Header avec logo personnalis√©
        import base64
        import os
        
        # Afficher le logo sans background
        logo_path = os.path.join(os.path.dirname(__file__), 'logo_climasene.png')
        if os.path.exists(logo_path):
            with open(logo_path, "rb") as f:
                logo_base64 = base64.b64encode(f.read()).decode()
            
            st.markdown(f"""
            <div style="
                display: flex;
                align-items: center;
                margin: 0 0 15px 0;
                padding: 0;
                gap: 12px;
            ">
                <img src="data:image/png;base64,{logo_base64}" 
                     style="
                        width: 85px; 
                        height: 85px; 
                        margin: 0;
                        padding: 0;
                        transform: rotate(-15deg);
                        flex-shrink: 0;
                     "/>
                <div style="
                    color: white;
                    font-weight: 600;
                    font-size: 16px;
                    line-height: 1.2;
                ">
                    Dashboard Climat S√©n√©gal
                </div>
            </div>
            """, unsafe_allow_html=True)
        else:
            # Fallback simple
            st.markdown("""
            <div style="text-align: center; margin-bottom: 30px;">
                <h3 style="color: white;">üå°Ô∏è ClimaS√©n√©</h3>
            </div>
            """, unsafe_allow_html=True)
        
        # Filtres
        st.markdown("**Filtres**")
        
        # Variable climatique
        variable = st.selectbox(
            "",
            options=["tasmax", "tasmin"],
            format_func=lambda x: "üå°Ô∏è Tasmax" if x == "tasmax" else "üå°Ô∏è TasMin",
            key="variable_select"
        )
        
        # P√©riode compacte
        col1, col2 = st.columns(2)
        with col1:
            start_year = st.number_input("", min_value=1960, max_value=2023, value=2010, key="start_year", label_visibility="collapsed")
        with col2:
            end_year = st.number_input("", min_value=1961, max_value=2024, value=2020, key="end_year", label_visibility="collapsed")
        
        # Localit√©s
        st.markdown("**Localit√©**")
        
        # R√©cup√©rer dynamiquement les localit√©s depuis l'API
        cities_from_api = get_available_localities_from_api()
        
        regions = {
            "üá∏üá≥ National": [
                {"name": "Moyenne nationale", "type": "national", "lat_idx": None, "lon_idx": None}
            ]
        }
        
        # Organiser les 94 villes par r√©gion administrative si l'API est accessible
        if cities_from_api:
            # Organiser par r√©gions administratives du S√©n√©gal
            regions_admin = {}
            
            for city in cities_from_api:
                city_info = {
                    "name": city['name'],
                    "type": "city",
                    "lat": city['latitude'],
                    "lon": city['longitude'],
                    "lat_idx": city['lat_idx'],
                    "lon_idx": city['lon_idx'],
                    "region": city.get('region', 'Autre'),
                    "city_type": city.get('type', 'Ville')
                }
                
                # Regrouper par r√©gion administrative
                region = city.get('region', 'Autre')
                region_key = f"üèõÔ∏è {region}"
                
                if region_key not in regions_admin:
                    regions_admin[region_key] = []
                regions_admin[region_key].append(city_info)
            
            # Ajouter toutes les r√©gions administratives
            regions.update(regions_admin)
        else:
            # Fallback am√©lior√© en cas d'erreur API
            regions["‚ö†Ô∏è Principales villes (Fallback)"] = [
                {"name": "Dakar", "type": "city", "lat": 14.7167, "lon": -17.4677, "lat_idx": 11, "lon_idx": 2, "region": "Dakar"},
                {"name": "Thi√®s", "type": "city", "lat": 14.7886, "lon": -16.926, "lat_idx": 11, "lon_idx": 4, "region": "Thi√®s"},
                {"name": "Saint-Louis", "type": "city", "lat": 16.0469, "lon": -16.4814, "lat_idx": 16, "lon_idx": 6, "region": "Saint-Louis"},
                {"name": "Ziguinchor", "type": "city", "lat": 12.5681, "lon": -16.2736, "lat_idx": 2, "lon_idx": 7, "region": "Ziguinchor"}
            ]
        
        # Cr√©er une liste plate pour le selectbox
        localities_list = []
        for region_name, cities in regions.items():
            localities_list.extend(cities)
        
        # Interface simplifi√©e pour les localit√©s
        locality_options = [loc["name"] for loc in localities_list]
        
        # Selectbox avec options filtr√©es
        selected_locality_name = st.selectbox(
            "",
            options=locality_options,
            key="sidebar_locality_select",
            label_visibility="collapsed"
        )
        
        selected_locality = next(loc for loc in localities_list if loc["name"] == selected_locality_name)
        
        # Export
        st.markdown("**Export**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            format_type = st.selectbox(
                "",
                options=["csv", "netcdf"],
                key="format_select",
                label_visibility="collapsed"
            )
        
        with col2:
            # Pr√©parer les donn√©es pour le t√©l√©chargement direct
            try:
                data_content = download_data_from_api(variable, start_year, end_year, format_type)
                if data_content:
                    filename = f"{selected_locality_name.replace(' ', '_')}_{variable}_{start_year}_{end_year}.{format_type}"
                    mime_type = "text/csv" if format_type == "csv" else "application/x-netcdf"
                    
                    # Bouton de t√©l√©chargement direct en un clic
                    st.download_button(
                        label="Export",
                        data=data_content,
                        file_name=filename,
                        mime=mime_type,
                        use_container_width=True,
                        type="primary"  # "primary" rend le bouton bleu dans Streamlit
                    )
                else:
                    st.button("‚ùå Donn√©es indisponibles", disabled=True, use_container_width=True)
            except Exception as e:
                st.button("‚ùå Erreur export", disabled=True, use_container_width=True)
            


                    # Ancien code de t√©l√©chargement automatique supprim√© car Streamlit ne permet pas de forcer le t√©l√©chargement sans interaction utilisateur.
                    # Le bouton de t√©l√©chargement direct est d√©j√† g√©r√© ci-dessus.
        
        # # Actualiser compact
        # if st.button("üîÑ", use_container_width=True, type="primary"):
        #     for key in list(st.session_state.keys()):
        #         if 'data' in key or 'loaded' in key:
        #             del st.session_state[key]
        #     st.rerun()
        
        # # Status mini
        # try:
        #     health_response = requests.get(f"{API_BASE_URL}/health", timeout=1)
        #     if health_response.status_code == 200:
        #         st.markdown("üü¢")
        #     else:
        #         st.markdown("üî¥")
        # except:
        #     st.markdown("üî¥")
        
        return variable, start_year, end_year, format_type, selected_locality_name, selected_locality

def main():
    
    st.markdown("""
    <style>
        .main > div { padding: 1rem 2rem; }
        h1 { color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px; }
    </style>
    """, unsafe_allow_html=True)
    
    variable, start_year, end_year, format_type, selected_locality_name, selected_locality = create_navigation_sidebar()
    
    st.title("Dashboard Climatique du S√©n√©gal")
    st.markdown("*Analyse des donn√©es climatiques NetCDF*")
    
    # V√©rifier si une localit√© a √©t√© s√©lectionn√©e via la carte
    if st.session_state.map_clicked_locality:
        # Mise √† jour depuis le clic sur la carte
        st.session_state.selected_locality = st.session_state.map_clicked_locality
        st.session_state.map_clicked_locality = None  # Reset
        st.session_state.update_charts = True
    
    # V√©rification de la s√©lection dans la sidebar
    if not selected_locality:
        st.info("S√©lectionnez une localit√© dans la barre lat√©rale pour voir les donn√©es")
        return
    
    analysis_mode = selected_locality["type"]
    lat_idx = selected_locality.get("lat_idx") 
    lon_idx = selected_locality.get("lon_idx")
    
    if analysis_mode == "national":
        st.info("Analyse nationale")
    else:
        st.info(f"Localit√© : **{selected_locality_name}**")
        
        with st.spinner(f"Chargement des donn√©es pour {selected_locality_name}..."):
            try:
                detailed_data = fetch_detailed_locality_data(
                    variable, start_year, end_year,
                    selected_locality.get('lat', 0),
                    selected_locality.get('lon', 0),
                    selected_locality_name
                )
                
                if detailed_data:
                    locality_data = {
                        'coords': {
                            'lat': selected_locality.get('lat', 0),
                            'lon': selected_locality.get('lon', 0)
                        },
                        'climate_data': detailed_data
                    }
                    
                    # show_locality_sidebar(selected_locality_name, locality_data, variable, start_year, end_year)
                    st.markdown("---")
                    show_locality_expander(selected_locality_name, locality_data, variable, start_year, end_year)
                    return
                    
                else:
                    st.error(f"Impossible de r√©cup√©rer les donn√©es pour {selected_locality_name}")
                    
            except Exception as e:
                st.error(f"Erreur lors du chargement: {e}")
    
    st.markdown("---")
    
    # Interface pour lancer le chargement des donn√©es
    col1, col2 = st.columns([3, 1])
    
    with col1:
        st.markdown(f"**Analyse s√©lectionn√©e :** {selected_locality_name}")
        st.markdown(f"**Variable :** {variable.upper()} | **P√©riode :** {start_year}-{end_year}")
    
    with col2:
        if 'data_loaded' not in st.session_state:
            load_data = st.button("üìä Charger les donn√©es", type="primary")
        else:
            col_a, col_b = st.columns(2)
            with col_a:
                load_data = st.button("üîÑ Actualiser", type="secondary")
            with col_b:
                if st.button("üóëÔ∏è R√©initialiser"):
                    st.session_state.pop('data_loaded', None)
                    st.rerun()
                load_data = False
    
    # Chargement des donn√©es seulement si le bouton est cliqu√©
    data = None
    if load_data or 'data_loaded' in st.session_state:
        st.session_state.data_loaded = True
        
        with st.spinner("üìÇ Extraction des donn√©es"):
            if analysis_mode == "national":
                data = fetch_data(variable, start_year, end_year)
                location_title = "S√©n√©gal (Nationale)"
            else:
                if lat_idx is not None and lon_idx is not None:
                    # üéØ MODE LOCALIT√â - AFFICHAGE IMM√âDIAT DES INFORMATIONS D√âTAILL√âES
                    
                    # 1. R√©cup√©rer les donn√©es climatiques compl√®tes
                    raw_data = fetch_locality_data(
                        variable, start_year, end_year, 
                        lat_idx, lon_idx, selected_locality['name']
                    )
                    
                    if raw_data:
                        # 2. Pr√©parer les donn√©es pour l'affichage d√©taill√©
                        detailed_data = fetch_detailed_locality_data(
                            variable, start_year, end_year,
                            selected_locality['coords']['lat'],
                            selected_locality['coords']['lon'],
                            selected_locality['name']
                        )
                        
                        locality_data = {
                            'coords': selected_locality['coords'],
                            'climate_data': detailed_data if detailed_data else {}
                        }
                        
                        # 3. === AFFICHAGE IMM√âDIAT DUAL : SIDEBAR + EXPANDER ===
                        st.success(f"‚úÖ Donn√©es charg√©es pour {selected_locality['name']}")
                        
                        # SIDEBAR : Informations permanentes et statistiques cl√©s
                        # show_locality_sidebar(selected_locality['name'], locality_data, variable, start_year, end_year)
                        
                        # EXPANDER : Analyses d√©taill√©es et graphiques complets  
                        st.markdown("---")
                        st.markdown("### üìä Analyse D√©taill√©e de la Localit√©")
                        show_locality_expander(selected_locality['name'], locality_data, variable, start_year, end_year)
                        
                        # 4. Adapter les donn√©es pour les graphiques principaux (si n√©cessaire)
                        data = adapt_locality_data_format(raw_data)
                        location_title = f"{selected_locality['name']} (Localit√© sp√©cifique)"
                        
                        # Message informatif
                        st.info("üí° **Double affichage activ√© :** Consultez la **sidebar** pour les statistiques rapides et l'**expander** ci-dessus pour l'analyse compl√®te.")
                        
                    else:
                        st.error(f"‚ùå Impossible de r√©cup√©rer les donn√©es pour {selected_locality['name']}")
                        data = None
                else:
                    st.error("‚ùå Probl√®me avec les indices de localit√©")
                    data = None
    
    # Affichage du contenu seulement si les donn√©es sont charg√©es
    if data is None and 'data_loaded' not in st.session_state:

        st.markdown("### üéØ Fonctionnalit√©s disponibles :")
        st.markdown("""
        - üìä **S√©ries temporelles** avec vos donn√©es NetCDF r√©elles
        - üìà **Statistiques d√©taill√©es** (min, max, moyenne, √©cart-type)
        - üå°Ô∏è **Climatologie mensuelle** 
        - üó∫Ô∏è **Carte interactive** avec marqueurs par ville
        - üìã **Analyse comparative** entre localit√©s
        - üìÇ **Export des donn√©es** en diff√©rents formats
        """)
        return
    
    if data is None:
        st.error("‚ùå Impossible de r√©cup√©rer les donn√©es NetCDF. V√©rifiez que le backend est d√©marr√©.")
        if st.button("üîÑ R√©essayer"):
            st.session_state.pop('data_loaded', None)
            st.rerun()
        return
    
    # Afficher le titre avec la localisation

    
    # Affichage des graphiques en grille 2x2
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìà S√©rie Temporelle")
        fig_ts = create_time_series(variable, start_year, end_year, data)
        st.plotly_chart(fig_ts, use_container_width=True)
        
        st.subheader("üìã R√©sum√© Statistique")
        fig_stats = create_statistics_summary(variable, start_year, end_year, data)
        st.plotly_chart(fig_stats, use_container_width=True)
    
    with col2:
        st.subheader("üìä Climatologie Moyenne")
        fig_clim = create_climatology(variable, start_year, end_year, data)
        st.plotly_chart(fig_clim, use_container_width=True)
        
        st.subheader("üó∫Ô∏è Repr√©sentation Spatiale")
        try:
            # R√©cup√©rer les donn√©es spatiales via l'API
            spatial_data = fetch_spatial_data(variable, start_year, end_year)
            if spatial_data:
                fig_spatial = create_spatial_map(variable, {"spatial": spatial_data})
                st.plotly_chart(fig_spatial, use_container_width=True)
            else:
                st.error("‚ùå Impossible de charger les donn√©es spatiales")
        except Exception as e:
            st.error(f"‚ùå Erreur lors du chargement des donn√©es spatiales: {e}")


    

    
    # Section interactive - Graphiques d√©taill√©s pour la localit√© s√©lectionn√©e
    st.markdown("---")
    
    # D√©tection du changement de localit√©
    locality_changed = check_locality_change()
    
    if locality_changed or st.session_state.update_charts:
        st.success(f"üéØ Analyse mise √† jour pour : **{selected_locality_name}**")
        st.session_state.update_charts = False
    
    # === SYST√àME EXPANDER + SIDEBAR POUR LES LOCALIT√âS ===
    
    # R√©cup√©rer les donn√©es d√©taill√©es pour la localit√© s√©lectionn√©e
    if analysis_mode == "national":
        detailed_data = fetch_data(variable, start_year, end_year)
        coords = {"lat": 14.5, "lon": -14.0}  # Centre du S√©n√©gal
    else:
        detailed_data = fetch_locality_data(variable, start_year, end_year, lat_idx, lon_idx, selected_locality_name)
        coords = {"lat": lat_idx, "lon": lon_idx}
    
    # Afficher automatiquement l'expander avec les d√©tails de la localit√©
    if detailed_data:
        locality_data = {
            "coords": coords,
            "climate_data": detailed_data
        }
        show_locality_expander(selected_locality_name, locality_data, variable, start_year, end_year)
    
    # Afficher la sidebar si une localit√© a √©t√© √©pingl√©e
    # if st.session_state.sidebar_locality and st.session_state.sidebar_name:
    #     show_locality_sidebar(
    #         st.session_state.sidebar_name, 
    #         st.session_state.sidebar_locality, 
    #         variable, start_year, end_year
    #     )
    
    # === SECTION DE COMPARAISON (SI ACTIV√âE) ===
    if st.session_state.get('comparison_mode', False):
        st.markdown("### üîÑ Mode Comparaison")
        
        cities_to_compare = st.multiselect(
            f"Comparer {selected_locality_name} avec:",
            options=['Dakar', 'Thi√®s', 'Kaolack', 'Saint-Louis', 'Tambacounda'],
            max_selections=3
        )
        
        if cities_to_compare:
            st.info(f"üéØ Comparaison: {selected_locality_name} vs {', '.join(cities_to_compare)}")
        
        if st.button("‚ùå Fermer comparaison"):
            st.session_state.comparison_mode = False
            st.rerun()
    
        
    # Message si aucune donn√©e disponible  
    if not detailed_data or not detailed_data.get('temperatures'):
        st.warning(f"‚ö†Ô∏è Aucune donn√©e disponible pour {selected_locality_name}")
        st.info("üí° Essayez une autre localit√© ou v√©rifiez la connexion API")

    
    # === FIN DE LA SECTION LOCALIT√â ===


if __name__ == "__main__":
    main()